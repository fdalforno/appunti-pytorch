{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intro\n",
    "=======\n",
    "Pytorch ha al suo interno dei moduli per creare agevolmente delle reti neuronali e per leggere i dataset il modulo per creare le nn è **torch.nn** mentre le classi per utilizzare i dataset sono **Dataset** e **DataLoader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "train_samples = 5000\n",
    "\n",
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True)\n",
    "X = X.astype('float32')\n",
    "y = y.astype('int64')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=train_samples, test_size=10000)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 784)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAESBJREFUeJzt3V9sXOWZx/Hfg2MSJ2mikP8JBmcjaIBIJCuTrGC1AhUquqoElSgqF1UqVU0vCtpKvVjgptwsQqttu1ysKrnbqEFqaSu1LFygbRFaxBah5g+gJiFAUHCIcf4qIGISSJw8e+ET1gXP+07mzJkzzvP9SMj2PHM8rwf/cmb8vOd9zd0FIJ7L6h4AgHoQfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQc3o6IPNmOG9vb2dfEgglLNnz2p8fNyauW+p8JvZnZIel9Qj6T/d/bHU/Xt7ezUwMFDmIQEkDA8PN33fll/2m1mPpP+Q9BVJ10u6z8yub/X7AeisMu/5N0h62933u/sZSb+WdFd7hgWgamXCv1LSwUlfjxS3/RUz22xmO8xsx/j4eImHA9BOZcI/1R8VPnd9sLsPufuguw/OmNHRvy8CSCgT/hFJ/ZO+vlLSaLnhAOiUMuHfLukaM1tlZpdL+oakZ9ozLABVa/l1uLuPm9n9kv6giVbfFnff07aRTSNlV0MyS7dlo662lHteUE6pN+Hu/qykZ9s0FgAdxPReICjCDwRF+IGgCD8QFOEHgiL8QFDMt21Slb328+fP13p8GWWelzr7+Jddlj7vlR3bdJijwJkfCIrwA0ERfiAowg8ERfiBoAg/EBStvkKZllXu2LKtuNz3T9WrbgPW2eor064r+7zkHjunG1qBnPmBoAg/EBThB4Ii/EBQhB8IivADQRF+IKhLps9f9fLW586da/nY3Nhy37vMPIJcP7tsPTe2VD871+vO9dJ7enpaPr7sY+eUPT6lXXMEOPMDQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCl+vxmNizppKRzksbdfbAdg6pC2Wvut23b1rD2wgsvJI999NFHk/V169Yl62vWrEnWX3rppYa1kydPJo89c+ZMqfqBAweS9bGxsYa1sn38GTPSv76p43PHVq3MHIR2acczcJu7H2/D9wHQQbzsB4IqG36X9Ecz22lmm9sxIACdUfZl/y3uPmpmSyQ9Z2ZvuPuLk+9Q/KOwWar/fRaA/1fqzO/uo8XHo5KekrRhivsMufuguw8SfqB7tBx+M5tjZl+48LmkL0va3a6BAahWmVPxUklPFW2JGZJ+5e7/3ZZRAahcy+F39/2SbmzjWJp5zMq+98aNG5P1BQsWNKxdddVVyWMfeOCBZP3dd99N1kdGRpL1hQsXNqzNmjUreezZs2eT9fHx8WR9yZIlyfp7773XsJb7uU+dOpWs5+Zm9Pb2JuvdKje/oV1o9QFBEX4gKMIPBEX4gaAIPxAU4QeC6qopd3Vuk/3BBx8k69u3b29Y27dvX/LYVLtLkkZHR5P1d955J1mfN29ew1qulZdbNrzs0t0rVqxoWFu2bFny2N2703PGjh9PX0yaujQ2dzlx7ueucmnuMsuhXwzO/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QVFf1+cvI9WVz9uzZk6w/9NBDDWvr169PHptb2jvX588tv526BDTXx1+8eHGynrtkN1cv02vPzQM4duxYsp7ql5edv1D1lvCdwJkfCIrwA0ERfiAowg8ERfiBoAg/EBThB4KaVn3+Kq/3z0lds//6668nj80tf132mvvcNtophw4dStYPHz6crN90003J+tKlSxvWcj93lVtVl/3endpGu0qc+YGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gqGyf38y2SPqqpKPuvra47QpJv5E0IGlY0r3u/n51w6xfnXsK5KSui587d27y2NmzZyfr/f39yXpqXf6c3M+dm7+QWw8g1YvP9enrnAfQqTkEzZz5fyHpzs/c9qCk5939GknPF18DmEay4Xf3FyWd+MzNd0naWny+VdLdbR4XgIq1+p5/qbsfkqTiY3otJwBdp/K5/Wa2WdJmSZoxY1pdSgBc0lo98x8xs+WSVHw82uiO7j7k7oPuPkj4ge7RavifkbSp+HyTpKfbMxwAnZINv5k9KellSV80sxEz+7akxyTdYWb7JN1RfA1gGsm+Dnf3+xqUvtTmsUxbZfv4ueP7+vqS9YGBgYa11atXJ4+dM2dOsp4bW5m1CHJrCbz11lvJeq4fnpoHUHWfPyc3R6ET6h8BgFoQfiAowg8ERfiBoAg/EBThB4K6ZKbc5VonZS+bTbW8yi4LPn/+/GR9cHAwWU+1Ai+//PLksWUvq92/f3+ynmrnHT3acGJoU3I/W5lLenNYuhvAtEX4gaAIPxAU4QeCIvxAUIQfCIrwA0F1VZ+/TO+0bK+9SrkVjNavX5+sz5w5s+XHHh0dTdZ37tyZrJ86dSpZz20/nppHkPv/3dvbm6zXeVlu7vetm38fL+DMDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBdVWfv05l+ra5Y3NrDeSuS89JPf7ChQuTx958883J+uHDh5P1N954I1kfGxtrWOvp6UkeW7ZPPx167XXizA8ERfiBoAg/EBThB4Ii/EBQhB8IivADQWX7/Ga2RdJXJR1197XFbY9I+o6kY8XdHnb3Z6saZDco0zP+5JNPkvXcNfWpLbglafHixRc7pE/l5iDkvnduz4HUuv0HDx5MHpva3luqdv2HqucIpNY5yM1/aJdmzvy/kHTnFLf/xN3XFf9d0sEHLkXZ8Lv7i5JOdGAsADqozHv++83sL2a2xcwWtG1EADqi1fD/VNJqSeskHZL0o0Z3NLPNZrbDzHbk1nsD0Dkthd/dj7j7OXc/L+lnkjYk7jvk7oPuPphbyBJA57QUfjNbPunLr0na3Z7hAOiUZlp9T0q6VdIiMxuR9ENJt5rZOkkuaVjSdyscI4AKWCevee7r6/NczzqlzDX1uZ7x2bNnk/XU3ytyf8sos7a9lP/ZUusBLFiQ/lts7v9HmT0DpPQ8gtz/k/379yfruT0JUm8zc29Bc/VcLz5XTz0vZdY5GB4e1unTp5uaAMEMPyAowg8ERfiBoAg/EBThB4Ii/EBQYabcVdnSzF1amrtsNifXCjxz5kzDWuqSWkkaGRlJ1pcsWZKsr1mzJlnv6+trWMstWX7jjTcm67mx5ZYVL6PK7b87hTM/EBThB4Ii/EBQhB8IivADQRF+ICjCDwR1yfT5c73wnDq3c871jMv0lMt+7yNHjiTrH374YbK+atWqhrWVK1cmj83Nj7j66quT9dRluXv27EkeW7aPPx3mAXDmB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgLpk+f06V8wDKbvdcdunuVL3s984dPzY2lqzv2rWrYS231sDGjRuT9dmzZyfrN9xwQ8NabnnsvXv3JutllV3joS1jqHsAAOpB+IGgCD8QFOEHgiL8QFCEHwiK8ANBZfv8ZtYv6QlJyySdlzTk7o+b2RWSfiNpQNKwpHvd/f3qhtq9qu7zl6nntsHOfe/c8Tmpfvb776d/XV599dVk/fbbb0/W586d27B22223JY89fPhwsn7y5Mlk/VK5nn9c0g/c/TpJfyfpe2Z2vaQHJT3v7tdIer74GsA0kQ2/ux9y91eKz09K2itppaS7JG0t7rZV0t1VDRJA+13Ue34zG5C0XtKfJS1190PSxD8QktJ7JwHoKk3P7TezuZJ+J+n77v5hs+9pzGyzpM1Sek01AJ3V1JnfzHo1Efxfuvvvi5uPmNnyor5c0tGpjnX3IXcfdPdBwg90j2z4beIU/3NJe939x5NKz0jaVHy+SdLT7R8egKo0cyq+RdI3Je0ys9eK2x6W9Jik35rZtyW9K+nr1QyxPXKXUOZaXqm3OWXbOqltrCXpyiuvTNZPnDjRsDY6Opo8dnx8PFnPtSlzz2uqnnsl+NFHHyXruecttYX3ddddlzz25ZdfTtZ3796drOd0QyswG353/5OkRiP9UnuHA6BTmOEHBEX4gaAIPxAU4QeCIvxAUIQfCOqSmXKX6zdX2a8uc6wk9fb2Juv9/f3JemoeQG4b61wvPbe89ooVK5L11PLas2bNSh67bNmyZD21/bckXXvttQ1rixYtSh6b25o816cvszR3p+YAcOYHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaCmVZ+/TP+zbF+2ylWIPv7442T9zTffTNbXrl3bsJa6pl3Kz39YvXp1sj5z5sxkPbV89vz585PH5vr8qT6+JG3YsKFhbWhoKHns8ePHk/Xc70s3XK+fw5kfCIrwA0ERfiAowg8ERfiBoAg/EBThB4KaVn3+MspcXy2V69uW3TMgt5X1tm3bGtZyvfLly5cn67lr5ufMmZOsz5s3r2Ft4cKFyWNzcwz27duXrN9zzz0NawcOHEgeW3UfvxvmAXDmB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgLHc9t5n1S3pC0jJJ5yUNufvjZvaIpO9IOlbc9WF3fzb1vfr6+nxgYKDsmFuS+zlz9VwvvsyxuXpubFUd24xcv7rK+RFl5m5cqn384eFhnT59uqkHb2aSz7ikH7j7K2b2BUk7zey5ovYTd/+3VgcKoD7Z8Lv7IUmHis9PmtleSSurHhiAal3U6yYzG5C0XtKfi5vuN7O/mNkWM1vQ4JjNZrbDzHaMj4+XGiyA9mk6/GY2V9LvJH3f3T+U9FNJqyWt08Qrgx9NdZy7D7n7oLsPVrkOHoCL01T4zaxXE8H/pbv/XpLc/Yi7n3P385J+JqnxaokAuk42/DbxZ8ufS9rr7j+edPvky8G+Jml3+4cHoCrNvA6/RdI3Je0ys9eK2x6WdJ+ZrZPkkoYlfbeSEXZIrjXT09PTsFa2nVa2LVR1Oy+lyuXUy0q187rhktq6NfPX/j9JmuqZSvb0AXQ3ZvgBQRF+ICjCDwRF+IGgCD8QFOEHggoz37bOvm5qjkDV6pwDUNZ0vax2uuDMDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBZZfubuuDmR2TNHlv5EWSjndsABenW8fWreOSGFur2jm2q919cTN37Gj4P/fgZjvcfbC2ASR069i6dVwSY2tVXWPjZT8QFOEHgqo7/EM1P35Kt46tW8clMbZW1TK2Wt/zA6hP3Wd+ADWpJfxmdqeZvWlmb5vZg3WMoREzGzazXWb2mpntqHksW8zsqJntnnTbFWb2nJntKz5OuU1aTWN7xMzeK56718zsH2saW7+Z/Y+Z7TWzPWb2T8XttT53iXHV8rx1/GW/mfVIekvSHZJGJG2XdJ+7v97RgTRgZsOSBt299p6wmf2DpDFJT7j72uK2f5V0wt0fK/7hXODu/9wlY3tE0ljdOzcXG8osn7yztKS7JX1LNT53iXHdqxqetzrO/Bskve3u+939jKRfS7qrhnF0PXd/UdKJz9x8l6StxedbNfHL03ENxtYV3P2Qu79SfH5S0oWdpWt97hLjqkUd4V8p6eCkr0fUXVt+u6Q/mtlOM9tc92CmsLTYNv3C9ulLah7PZ2V3bu6kz+ws3TXPXSs7XrdbHeGfam2lbmo53OLufyvpK5K+V7y8RXOa2rm5U6bYWbortLrjdbvVEf4RSf2Tvr5S0mgN45iSu48WH49Kekrdt/vwkQubpBYfj9Y8nk91087NU+0srS547rppx+s6wr9d0jVmtsrMLpf0DUnP1DCOzzGzOcUfYmRmcyR9Wd23+/AzkjYVn2+S9HSNY/kr3bJzc6OdpVXzc9dtO17XMsmnaGX8u6QeSVvc/V86PogpmNnfaOJsL02sbPyrOsdmZk9KulUTV30dkfRDSf8l6beSrpL0rqSvu3vH//DWYGy3auKl66c7N194j93hsf29pP+VtEvS+eLmhzXx/rq25y4xrvtUw/PGDD8gKGb4AUERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8I6v8AIR6YfHyHtmIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "pyplot.imshow(X_train[0].reshape((28, 28)), cmap=\"gray\")\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valore minimo 0 massimo 9\n"
     ]
    }
   ],
   "source": [
    "print(\"Valore minimo {0} massimo {1}\".format(y_train.min(), y_train.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pytorch usa come struttura base il tensore *torch.tensor* dobbiamo quindi convertire l'array numpy in un tensore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stai usando la versione di pytorch 1.4.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"Stai usando la versione di pytorch {0}\".format(torch.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, X_test, y_test = map(\n",
    "    torch.from_numpy , (X_train, y_train, X_test, y_test)\n",
    ")\n",
    "\n",
    "n, c = x_train.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Network da zero\n",
    "=======\n",
    "\n",
    "mi vado a costruire una rete neuronale da zero senza l'uso del modulo **torch.nn** mi vado a creare i pesi con una inizializzazione random utilizzando l'inizializzaione di Xavier \n",
    "\n",
    "\\begin{equation*}\n",
    "\\frac{1}{\\sqrt{n}}\n",
    "\\end{equation*}\n",
    "\n",
    "sia il parametro weights che il parametro bias devono avere impostato reqires_grad, questo fa si che pytorch si vada a segnare tutte le operazioni fatte sul tensore e calcolerà in automatico il gradiente nella fase di back-propagation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Nota:</b> il parametro weights ha impostato requires_grad dopo l'inizializzazione in quanto non vogliamo che l'inizializzazione stessa finisca nel calcolo del gradiente\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "weights = torch.randn(784, 10) / math.sqrt(784)\n",
    "weights.requires_grad_()\n",
    "bias = torch.zeros(10, requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ci creiamo la funzione di softmax e il forward del modello, la parte di backpropagation viene fatta in automatico da pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x):\n",
    "    return x - x.exp().sum(-1).log().unsqueeze(-1)\n",
    "\n",
    "def model(xb):\n",
    "    return log_softmax(xb @ weights + bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-3.4385, -3.0876, -2.6466, -2.7132, -3.0494, -3.9457, -1.2683, -2.1686,\n",
      "        -3.6089, -1.2187], grad_fn=<SelectBackward>) torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "bs = 64  # batch size\n",
    "\n",
    "xb = x_train[0:bs]  # a mini-batch from x\n",
    "preds = model(xb)  # predictions\n",
    "preds[0], preds.shape\n",
    "print(preds[0], preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "loss_func = F.cross_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nella cella superiore abbiamo usato un nuovo pezzo *torch.nn.functional* questo modulo contiene tutte le funzioni che ci servono per calcolare la funzione di costo (loss) nel nostro caso la cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6991, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "yb = y_train[0:bs]\n",
    "print(loss_func(preds, yb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(out, yb):\n",
    "    preds = torch.argmax(out, dim=1)\n",
    "    return (preds == yb).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1094)\n"
     ]
    }
   ],
   "source": [
    "print(accuracy(preds, yb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "lr = 0.01  # learning rate\n",
    "epochs = 10  # how many epochs to train for\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i in range((n - 1) // bs + 1):\n",
    "        #set_trace()\n",
    "        start_i = i * bs\n",
    "        end_i = start_i + bs\n",
    "        xb = x_train[start_i:end_i]\n",
    "        yb = y_train[start_i:end_i]\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "\n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            weights -= weights.grad * lr\n",
    "            bias -= bias.grad * lr\n",
    "            weights.grad.zero_()\n",
    "            bias.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4328, grad_fn=<NllLossBackward>) tensor(0.8849)\n"
     ]
    }
   ],
   "source": [
    "print(loss_func(model(X_test), y_test), accuracy(model(X_test), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sistemiamo il codice con nn.Module\n",
    "====="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class Mnist_Logistic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.weights = nn.Parameter(torch.randn(784, 10) / math.sqrt(784))\n",
    "        self.bias = nn.Parameter(torch.zeros(10))\n",
    "\n",
    "    def forward(self, xb):\n",
    "        return xb @ self.weights + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
